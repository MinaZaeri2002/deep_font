{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VXcxTXHCR6ZN"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image, ImageFilter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting zip files\n",
        "with zipfile.ZipFile(\"font_patch.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "print(\"font_patch.zip extracted successfully.\")\n",
        "\n",
        "with zipfile.ZipFile(\"sample.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "print(\"sample.zip extracted successfully.\")"
      ],
      "metadata": {
        "id": "S9HTKmwLF30t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dce1d4f-6eaf-46c8-a2e9-9ae7bf59fa3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "font_patch.zip extracted successfully.\n",
            "sample.zip extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset for handling image data\n",
        "class FontPatchDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('L')  # Grayscale\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "SxyPjxxKF8hS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing functions\n",
        "def pil_image(img_path):\n",
        "    pil_im = Image.open(img_path).convert('L')\n",
        "    return pil_im.resize((105, 105))\n",
        "\n",
        "def noise_image(pil_im):\n",
        "    img_array = np.asarray(pil_im)\n",
        "    noisy_img = img_array + np.random.normal(0.0, 5, img_array.shape)  # Add Gaussian noise\n",
        "    noisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
        "    return Image.fromarray(np.uint8(noisy_img_clipped)).resize((105, 105))\n",
        "\n",
        "def blur_image(pil_im):\n",
        "    return pil_im.filter(ImageFilter.GaussianBlur(radius=3)).resize((105, 105))"
      ],
      "metadata": {
        "id": "HFjWPC0jGhXT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert label from string to integer\n",
        "def conv_label(label):\n",
        "    label_mapping = {\n",
        "                      'borna': 0,\n",
        "                      'dana': 1,\n",
        "                      'delnia': 2,\n",
        "                      'doran': 3,\n",
        "                      'hakaza': 4,\n",
        "                      'hasti': 5,\n",
        "                      'iransans': 6,\n",
        "                      'kook': 7,\n",
        "                      'liana': 8,\n",
        "                      'melli': 9,\n",
        "                      'noora': 10,\n",
        "                      'paradox': 11,\n",
        "                      'parsa': 12,\n",
        "                      'pesteh': 13,\n",
        "                      'potk': 14,\n",
        "                      'quarantine': 15,\n",
        "                      'radio': 16,\n",
        "                      'shoor': 17,\n",
        "                      'veno': 18,\n",
        "                      'yekan-bakh': 19\n",
        "\n",
        "                    }\n",
        "    return label_mapping.get(label)"
      ],
      "metadata": {
        "id": "ejwPUTh4IUwt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image paths and labels\n",
        "image_paths = sorted([os.path.join(root, name) for root, _, files in os.walk(\"font_patch/\") for name in files])\n",
        "random.shuffle(image_paths)\n",
        "labels = [conv_label(os.path.split(os.path.dirname(path))[-1]) for path in image_paths]\n",
        "\n"
      ],
      "metadata": {
        "id": "tYxsGQCuId65"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "pOqTishwIisE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((105, 105)),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.5),\n",
        "    transforms.RandomApply([transforms.Lambda(noise_image)], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((105, 105)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "ff6zNmF5Iyix"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and dataloaders\n",
        "train_dataset = FontPatchDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = FontPatchDataset(test_paths, test_labels, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "aGfBqpx1Izr7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN model with correct input size for fc1\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=48)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=24)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.convT1 = nn.ConvTranspose2d(128, 128, kernel_size=24, stride=2, padding=12)\n",
        "        self.convT2 = nn.ConvTranspose2d(128, 64, kernel_size=12, stride=2, padding=6)\n",
        "\n",
        "        # Updated input size for fc1\n",
        "        self.fc1 = nn.Linear(2304, 4096)  # 6*6*64 = 2304\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 20)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.convT1(x))\n",
        "        x = F.relu(self.convT2(x))\n",
        "\n",
        "        # Flatten the feature map\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Forward pass through fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QF0gpCGWI3q3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, loss function, and optimizer initialization\n",
        "model = CNNModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-6)"
      ],
      "metadata": {
        "id": "4yXIVEUpJAga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 250\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "atgUhMCoLgcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68852fc6-46ca-4dcb-a2c8-d077efee3e3f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/250], Loss: 2.997074762980143\n",
            "Epoch [2/250], Loss: 2.9953485329945884\n",
            "Epoch [3/250], Loss: 2.996675491333008\n",
            "Epoch [4/250], Loss: 2.99501363436381\n",
            "Epoch [5/250], Loss: 2.9942406018575034\n",
            "Epoch [6/250], Loss: 2.993678569793701\n",
            "Epoch [7/250], Loss: 2.9908430576324463\n",
            "Epoch [8/250], Loss: 2.9923737049102783\n",
            "Epoch [9/250], Loss: 2.9909818172454834\n",
            "Epoch [10/250], Loss: 2.9880871772766113\n",
            "Epoch [11/250], Loss: 2.990159193674723\n",
            "Epoch [12/250], Loss: 2.9863289992014566\n",
            "Epoch [13/250], Loss: 2.98432993888855\n",
            "Epoch [14/250], Loss: 2.9852046966552734\n",
            "Epoch [15/250], Loss: 2.98054830233256\n",
            "Epoch [16/250], Loss: 2.980490207672119\n",
            "Epoch [17/250], Loss: 2.9772210915883384\n",
            "Epoch [18/250], Loss: 2.9782461325327554\n",
            "Epoch [19/250], Loss: 2.9717363516489663\n",
            "Epoch [20/250], Loss: 2.967818021774292\n",
            "Epoch [21/250], Loss: 2.9564491907755532\n",
            "Epoch [22/250], Loss: 2.9454403718312583\n",
            "Epoch [23/250], Loss: 2.921522617340088\n",
            "Epoch [24/250], Loss: 2.8729962507883706\n",
            "Epoch [25/250], Loss: 2.820241928100586\n",
            "Epoch [26/250], Loss: 2.7439422607421875\n",
            "Epoch [27/250], Loss: 2.703925848007202\n",
            "Epoch [28/250], Loss: 2.7320121924082437\n",
            "Epoch [29/250], Loss: 2.6708818276723227\n",
            "Epoch [30/250], Loss: 2.684952179590861\n",
            "Epoch [31/250], Loss: 2.6826231479644775\n",
            "Epoch [32/250], Loss: 2.6990391413370767\n",
            "Epoch [33/250], Loss: 2.6259281635284424\n",
            "Epoch [34/250], Loss: 2.6700264612833657\n",
            "Epoch [35/250], Loss: 2.6609200636545816\n",
            "Epoch [36/250], Loss: 2.660380204518636\n",
            "Epoch [37/250], Loss: 2.6414353052775064\n",
            "Epoch [38/250], Loss: 2.695796330769857\n",
            "Epoch [39/250], Loss: 2.6100194454193115\n",
            "Epoch [40/250], Loss: 2.599154551823934\n",
            "Epoch [41/250], Loss: 2.69063409169515\n",
            "Epoch [42/250], Loss: 2.6859520276387534\n",
            "Epoch [43/250], Loss: 2.664081255594889\n",
            "Epoch [44/250], Loss: 2.7312708695729575\n",
            "Epoch [45/250], Loss: 2.643273115158081\n",
            "Epoch [46/250], Loss: 2.571418205897013\n",
            "Epoch [47/250], Loss: 2.5416534741719565\n",
            "Epoch [48/250], Loss: 2.571578025817871\n",
            "Epoch [49/250], Loss: 2.530647118886312\n",
            "Epoch [50/250], Loss: 2.538632790247599\n",
            "Epoch [51/250], Loss: 2.477147420247396\n",
            "Epoch [52/250], Loss: 2.499275286992391\n",
            "Epoch [53/250], Loss: 2.5807863076527915\n",
            "Epoch [54/250], Loss: 2.5025232632954917\n",
            "Epoch [55/250], Loss: 2.4974971612294516\n",
            "Epoch [56/250], Loss: 2.502436399459839\n",
            "Epoch [57/250], Loss: 2.457904020945231\n",
            "Epoch [58/250], Loss: 2.507380962371826\n",
            "Epoch [59/250], Loss: 2.4623019695281982\n",
            "Epoch [60/250], Loss: 2.382545073827108\n",
            "Epoch [61/250], Loss: 2.3748676776885986\n",
            "Epoch [62/250], Loss: 2.3000009854634604\n",
            "Epoch [63/250], Loss: 2.3286388715108237\n",
            "Epoch [64/250], Loss: 2.2099905411402383\n",
            "Epoch [65/250], Loss: 2.257851759592692\n",
            "Epoch [66/250], Loss: 2.156435171763102\n",
            "Epoch [67/250], Loss: 2.1969500382741294\n",
            "Epoch [68/250], Loss: 2.1644137700398765\n",
            "Epoch [69/250], Loss: 2.1365153789520264\n",
            "Epoch [70/250], Loss: 2.0745352109273276\n",
            "Epoch [71/250], Loss: 2.1722723642985025\n",
            "Epoch [72/250], Loss: 2.1486366192499795\n",
            "Epoch [73/250], Loss: 2.1276713609695435\n",
            "Epoch [74/250], Loss: 1.936992883682251\n",
            "Epoch [75/250], Loss: 2.107644279797872\n",
            "Epoch [76/250], Loss: 2.082486112912496\n",
            "Epoch [77/250], Loss: 1.979066014289856\n",
            "Epoch [78/250], Loss: 2.001061797142029\n",
            "Epoch [79/250], Loss: 2.020703752835592\n",
            "Epoch [80/250], Loss: 1.896874189376831\n",
            "Epoch [81/250], Loss: 1.9264148076375325\n",
            "Epoch [82/250], Loss: 1.7966185410817463\n",
            "Epoch [83/250], Loss: 1.8288710117340088\n",
            "Epoch [84/250], Loss: 1.7540268103281658\n",
            "Epoch [85/250], Loss: 1.7355979681015015\n",
            "Epoch [86/250], Loss: 1.5880704323450725\n",
            "Epoch [87/250], Loss: 1.5077116092046101\n",
            "Epoch [88/250], Loss: 1.5231253306070964\n",
            "Epoch [89/250], Loss: 1.524135152498881\n",
            "Epoch [90/250], Loss: 1.4440562725067139\n",
            "Epoch [91/250], Loss: 1.3806482553482056\n",
            "Epoch [92/250], Loss: 1.360496997833252\n",
            "Epoch [93/250], Loss: 1.2564863363901775\n",
            "Epoch [94/250], Loss: 1.3295807043711345\n",
            "Epoch [95/250], Loss: 1.2822233438491821\n",
            "Epoch [96/250], Loss: 1.187941571076711\n",
            "Epoch [97/250], Loss: 1.0354616045951843\n",
            "Epoch [98/250], Loss: 1.0887771050135295\n",
            "Epoch [99/250], Loss: 0.964807411034902\n",
            "Epoch [100/250], Loss: 1.0333667596181233\n",
            "Epoch [101/250], Loss: 0.8077994187672933\n",
            "Epoch [102/250], Loss: 0.8612236579259237\n",
            "Epoch [103/250], Loss: 1.1925434072812398\n",
            "Epoch [104/250], Loss: 0.9632505178451538\n",
            "Epoch [105/250], Loss: 0.9650188287099203\n",
            "Epoch [106/250], Loss: 0.923998216787974\n",
            "Epoch [107/250], Loss: 1.1834172407786052\n",
            "Epoch [108/250], Loss: 0.9840564330418905\n",
            "Epoch [109/250], Loss: 0.9005093375841776\n",
            "Epoch [110/250], Loss: 0.8751354614893595\n",
            "Epoch [111/250], Loss: 0.6591807007789612\n",
            "Epoch [112/250], Loss: 0.5867335100968679\n",
            "Epoch [113/250], Loss: 0.47607214252154034\n",
            "Epoch [114/250], Loss: 0.3207756231228511\n",
            "Epoch [115/250], Loss: 0.4089258710543315\n",
            "Epoch [116/250], Loss: 0.4366077184677124\n",
            "Epoch [117/250], Loss: 0.2779332995414734\n",
            "Epoch [118/250], Loss: 0.33537132541338605\n",
            "Epoch [119/250], Loss: 0.20758614440759024\n",
            "Epoch [120/250], Loss: 0.20059194167455038\n",
            "Epoch [121/250], Loss: 0.1302682856718699\n",
            "Epoch [122/250], Loss: 0.2324557527899742\n",
            "Epoch [123/250], Loss: 0.10341077484190464\n",
            "Epoch [124/250], Loss: 0.17577490707238516\n",
            "Epoch [125/250], Loss: 0.1861137772599856\n",
            "Epoch [126/250], Loss: 0.1509064386288325\n",
            "Epoch [127/250], Loss: 0.17707349359989166\n",
            "Epoch [128/250], Loss: 0.11341733733812968\n",
            "Epoch [129/250], Loss: 0.22469519078731537\n",
            "Epoch [130/250], Loss: 0.14169931411743164\n",
            "Epoch [131/250], Loss: 0.11620626722772916\n",
            "Epoch [132/250], Loss: 0.21877842644850412\n",
            "Epoch [133/250], Loss: 0.05372760444879532\n",
            "Epoch [134/250], Loss: 0.1280511220296224\n",
            "Epoch [135/250], Loss: 0.276119627058506\n",
            "Epoch [136/250], Loss: 0.2168565864364306\n",
            "Epoch [137/250], Loss: 0.17180948331952095\n",
            "Epoch [138/250], Loss: 0.2447918802499771\n",
            "Epoch [139/250], Loss: 0.2654666354258855\n",
            "Epoch [140/250], Loss: 0.22587567567825317\n",
            "Epoch [141/250], Loss: 0.08222895736495654\n",
            "Epoch [142/250], Loss: 0.20520404974619547\n",
            "Epoch [143/250], Loss: 0.12654428742825985\n",
            "Epoch [144/250], Loss: 0.07870685557524364\n",
            "Epoch [145/250], Loss: 0.07741478085517883\n",
            "Epoch [146/250], Loss: 0.06896486257513364\n",
            "Epoch [147/250], Loss: 0.019571323568622272\n",
            "Epoch [148/250], Loss: 0.048556944355368614\n",
            "Epoch [149/250], Loss: 0.020264969517787296\n",
            "Epoch [150/250], Loss: 0.06063456988583008\n",
            "Epoch [151/250], Loss: 0.020773152510325115\n",
            "Epoch [152/250], Loss: 0.03137320280075073\n",
            "Epoch [153/250], Loss: 0.05880859370032946\n",
            "Epoch [154/250], Loss: 0.07720993583401044\n",
            "Epoch [155/250], Loss: 0.11183208134025335\n",
            "Epoch [156/250], Loss: 0.028585464072724182\n",
            "Epoch [157/250], Loss: 0.05366107697288195\n",
            "Epoch [158/250], Loss: 0.011389810126274824\n",
            "Epoch [159/250], Loss: 0.03765544854104519\n",
            "Epoch [160/250], Loss: 0.03220943578829368\n",
            "Epoch [161/250], Loss: 0.021661413212617237\n",
            "Epoch [162/250], Loss: 0.020098980360974867\n",
            "Epoch [163/250], Loss: 0.006426384672522545\n",
            "Epoch [164/250], Loss: 0.02344809767479698\n",
            "Epoch [165/250], Loss: 0.006775036454200745\n",
            "Epoch [166/250], Loss: 0.02359443934013446\n",
            "Epoch [167/250], Loss: 0.00332536866577963\n",
            "Epoch [168/250], Loss: 0.005933044555907448\n",
            "Epoch [169/250], Loss: 0.06453697942197323\n",
            "Epoch [170/250], Loss: 0.04148271959275007\n",
            "Epoch [171/250], Loss: 0.07951433956623077\n",
            "Epoch [172/250], Loss: 0.07107701369871695\n",
            "Epoch [173/250], Loss: 0.018424756204088528\n",
            "Epoch [174/250], Loss: 0.16959552528957525\n",
            "Epoch [175/250], Loss: 0.1035714593405525\n",
            "Epoch [176/250], Loss: 0.334078311920166\n",
            "Epoch [177/250], Loss: 0.3050500104824702\n",
            "Epoch [178/250], Loss: 0.1059341070552667\n",
            "Epoch [179/250], Loss: 0.4116038829088211\n",
            "Epoch [180/250], Loss: 0.23494113981723785\n",
            "Epoch [181/250], Loss: 0.14893590410550436\n",
            "Epoch [182/250], Loss: 0.23634134978055954\n",
            "Epoch [183/250], Loss: 0.29446225116650265\n",
            "Epoch [184/250], Loss: 0.155124269425869\n",
            "Epoch [185/250], Loss: 0.21888586630423865\n",
            "Epoch [186/250], Loss: 0.17739694565534592\n",
            "Epoch [187/250], Loss: 0.11752251784006755\n",
            "Epoch [188/250], Loss: 0.058452477057774864\n",
            "Epoch [189/250], Loss: 0.22366492450237274\n",
            "Epoch [190/250], Loss: 0.07049743582804997\n",
            "Epoch [191/250], Loss: 0.33030199507872265\n",
            "Epoch [192/250], Loss: 0.10071556456387043\n",
            "Epoch [193/250], Loss: 0.5607864757378896\n",
            "Epoch [194/250], Loss: 0.1159227229654789\n",
            "Epoch [195/250], Loss: 0.45899026095867157\n",
            "Epoch [196/250], Loss: 0.6483078350623449\n",
            "Epoch [197/250], Loss: 0.543231134613355\n",
            "Epoch [198/250], Loss: 0.4355228791634242\n",
            "Epoch [199/250], Loss: 0.3237462143103282\n",
            "Epoch [200/250], Loss: 0.2939416468143463\n",
            "Epoch [201/250], Loss: 0.180095707376798\n",
            "Epoch [202/250], Loss: 0.17947494983673096\n",
            "Epoch [203/250], Loss: 0.2118049052854379\n",
            "Epoch [204/250], Loss: 0.07367715239524841\n",
            "Epoch [205/250], Loss: 0.1883078378935655\n",
            "Epoch [206/250], Loss: 0.04721090756356716\n",
            "Epoch [207/250], Loss: 0.27230756854017574\n",
            "Epoch [208/250], Loss: 0.16068473954995474\n",
            "Epoch [209/250], Loss: 0.2817988209426403\n",
            "Epoch [210/250], Loss: 0.17725448062022528\n",
            "Epoch [211/250], Loss: 0.1278963585694631\n",
            "Epoch [212/250], Loss: 0.04558565219243368\n",
            "Epoch [213/250], Loss: 0.14980541169643402\n",
            "Epoch [214/250], Loss: 0.06940309889614582\n",
            "Epoch [215/250], Loss: 0.042440702207386494\n",
            "Epoch [216/250], Loss: 0.04810729126135508\n",
            "Epoch [217/250], Loss: 0.0588553361594677\n",
            "Epoch [218/250], Loss: 0.017538084648549557\n",
            "Epoch [219/250], Loss: 0.016112721525132656\n",
            "Epoch [220/250], Loss: 0.07466695209344228\n",
            "Epoch [221/250], Loss: 0.012915872347851595\n",
            "Epoch [222/250], Loss: 0.04936417378485203\n",
            "Epoch [223/250], Loss: 0.01438766454036037\n",
            "Epoch [224/250], Loss: 0.005015599308535457\n",
            "Epoch [225/250], Loss: 0.030899581033736467\n",
            "Epoch [226/250], Loss: 0.006498054756472508\n",
            "Epoch [227/250], Loss: 0.012216086208354682\n",
            "Epoch [228/250], Loss: 0.0022806850417206683\n",
            "Epoch [229/250], Loss: 0.0024440943573911986\n",
            "Epoch [230/250], Loss: 0.005824174382723868\n",
            "Epoch [231/250], Loss: 0.02281941349307696\n",
            "Epoch [232/250], Loss: 0.0015478009784904618\n",
            "Epoch [233/250], Loss: 0.003921318605231742\n",
            "Epoch [234/250], Loss: 0.004429305670782924\n",
            "Epoch [235/250], Loss: 0.006687643937766552\n",
            "Epoch [236/250], Loss: 0.009694002568721771\n",
            "Epoch [237/250], Loss: 0.012778617111810794\n",
            "Epoch [238/250], Loss: 0.025783176359254867\n",
            "Epoch [239/250], Loss: 0.006706676247025219\n",
            "Epoch [240/250], Loss: 0.004863489652052522\n",
            "Epoch [241/250], Loss: 0.014108707352230946\n",
            "Epoch [242/250], Loss: 0.019577171769924462\n",
            "Epoch [243/250], Loss: 0.0013902985665481538\n",
            "Epoch [244/250], Loss: 0.002730277463948975\n",
            "Epoch [245/250], Loss: 0.002425264761162301\n",
            "Epoch [246/250], Loss: 0.004990085260942578\n",
            "Epoch [247/250], Loss: 0.004310447373427451\n",
            "Epoch [248/250], Loss: 0.0006735354836564511\n",
            "Epoch [249/250], Loss: 0.0005488732701148061\n",
            "Epoch [250/250], Loss: 0.0005642999506865939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "torch.save(model.state_dict(), 'model_weights.pth')\n",
        "print(\"Model weights saved successfully.\")"
      ],
      "metadata": {
        "id": "1RXcgr-LQFp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318cb062-9f3e-44f9-ef6b-2aa165f92dc1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
      ],
      "metadata": {
        "id": "_rvSHr5hQHos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7734cca-a76c-48df-e291-c9b12190c793"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image and test the model\n",
        "img_path = \"/content/sample/doran1.jpg\"\n",
        "img = Image.open(img_path).convert('L')\n",
        "img = blur_image(img)\n",
        "img = test_transform(img).unsqueeze(0)  # Add batch dimensionء‌"
      ],
      "metadata": {
        "id": "8ILd7a44QKb9"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model weights for inference\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()  # Set model to evaluation mode"
      ],
      "metadata": {
        "id": "L_6H6MGWQTlm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44f7de2-8a0d-4cf6-ec4b-2281f214e211"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-2b7ebc7c052b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('model_weights.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(48, 48), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(24, 24), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convT1): ConvTranspose2d(128, 128, kernel_size=(24, 24), stride=(2, 2), padding=(12, 12))\n",
              "  (convT2): ConvTranspose2d(128, 64, kernel_size=(12, 12), stride=(2, 2), padding=(6, 6))\n",
              "  (fc1): Linear(in_features=2304, out_features=4096, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rev_conv_label(label):\n",
        "    label_mapping = {\n",
        "                      0:'borna',\n",
        "                      1: 'dana',\n",
        "                      2: 'delnia',\n",
        "                      3: 'doran',\n",
        "                      4: 'hakaza',\n",
        "                      5: 'hasti',\n",
        "                      6: 'iransans',\n",
        "                      7: 'kook',\n",
        "                      8: 'liana',\n",
        "                      9: 'melli',\n",
        "                      10: 'noora',\n",
        "                      11: 'paradox',\n",
        "                      12: 'parsa',\n",
        "                      13: 'pesteh',\n",
        "                      14: 'potk',\n",
        "                      15: 'quarantine',\n",
        "                      16: 'radio',\n",
        "                      17: 'shoor',\n",
        "                      18: 'veno',\n",
        "                      19: 'yekan-bakh'\n",
        "                    }\n",
        "    return label_mapping.get(label)\n"
      ],
      "metadata": {
        "id": "yR600t6CQX5p"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(img)\n",
        "    predicted_probabilities = torch.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "\n",
        "    # Get the top 3 classes and their probabilities\n",
        "    top3_probabilities, top3_classes = torch.topk(predicted_probabilities, 3)\n"
      ],
      "metadata": {
        "id": "fct_2BaHSBvC"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the predicted labels to strings and calculate percentages\n",
        "labels = [rev_conv_label(top3_classes[0][i].item()) for i in range(3)]\n",
        "percentages = [top3_probabilities[0][i].item() * 100 for i in range(3)]  # Convert to percentages\n"
      ],
      "metadata": {
        "id": "KikNm3UASTFl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image with predicted labels and similarity percentages\n",
        "img_np = img.numpy().reshape(105, 105) # Shape will be (105, 105)"
      ],
      "metadata": {
        "id": "g_sTzTFSXTcy"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the imageim\n",
        "img = Image.open(img_path).convert('L')\n",
        "plt.imshow(img, cmap='gray')\n",
        "\n",
        "# Display top 3 labels and percentages\n",
        "for i in range(3):\n",
        "    plt.text(20, i * 110, f'{labels[i]}', bbox={'facecolor': 'white',\n",
        "                                                  'edgecolor': 'white',\n",
        "                                                  'pad': 5})\n",
        "\n",
        "\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TPfqd6YwQb5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "a9ac6e0a-d93d-4d17-a456-016cb9097770"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mluaQyEbS5C0"
      },
      "execution_count": 74,
      "outputs": []
    }
  ]
}